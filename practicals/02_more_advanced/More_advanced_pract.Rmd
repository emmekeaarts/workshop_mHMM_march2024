---
title: "More advanced matters"
mainfont: Arial
params:
  answers: true
fontsize: 12pt
urlcolor: blue
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    theme: paper
    pandoc_args: --output=More_advanced_pract_answers.html
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE)
library(mHMMbayes)
library(ggplot2)
library(viridis)
library(reshape2)
emotion_data <- readRDS("./data/data_Rowland2020.rds")
out_2st_emotion <- readRDS("./data/out_2st_emotion.rds")
```

This is the second practical, we will dive into more advanced matters: model selection, subject specific parameters, covariates, and model fit. We continue with the same dataset: the open access dataset from Rowland and Wenzel (2020) containing the affective experiences *happy*, *excited*, *relaxed*, *satisfied*, *angry*, *anxious*, *depressed*, and *sad*, measured six times a day for 40 days in total. In contrary to the first practical, the different parts do not build upon one another, so you are free to choose any order you like, starting with the topic you find most interesting. There is quite some material and it is likely you will not be able to finish all of them (most likely around 2 topics), but the topics you have skipped can be completed at your own convenience at a later moment. 

The answers to the practicals are available in the `*_answers.html` files. Try to work out the answer yourself (e.g., inspecting help files and examples in them provided in the `mHMMbayes` package, looking at the tutorial vignette available online) before looking at this!

In all practicals in this workshop, we make use of the `mHMMbayes` package, version 1.0.0. You can load the package like 

```{r, eval=FALSE}
library(mHMMbayes)
```

In this practical, we will also use the following packages:

```{r, eval=FALSE}
library(ggplot2)
library(reshape2)
library(viridis)    # optional
```

## Model selection

### Fit models with a plausible number of states

One of the challenges when using hidden Markov models is the number of states to choose. Here, we will limit ourselves to models with 2, 3, and 4 states. As model checking is discussed at a later point in the practical, we will investigate the different models based on the state composition and the model fit criterion AIC. The 2-state model was fitted in the first practical, and saved in the object `out_2st_emotion`. 

---

**Exercise 1**
Fit a 3- and 4- state multilevel HMM model, and save the fitted models in the objects `out_3st_emotion` and `out_4st_emotion`, respectively. Again we recommend 500 MCMC iterations and a burn-in of 200, or a bit less if this takes a lot of time on your laptop. Note that with these new models, also new starting values and and hyper-prior parameter values have to be specified. To speed up the process somewhat, below a suggestion for new starting and prior values is given in a starter script. 

```{r, echo = TRUE}
####################
# 3 state model 
####################

## general model properties
m <- 3
n_dep <- 8

## starting values for gamma
start_gamma_3st <- matrix(c(0.8, 0.1, 0.1,
                        0.1, 0.8, 0.1,
                        0.1, 0.1, 0.8), byrow = TRUE, ncol = m, nrow = m)

## starting values for the emission distribution 
start_emiss_3st <- list(matrix(c(80, 10,                                     # happy
                             50, 10,
                             20, 10), byrow = TRUE, ncol = 2, nrow = m), 
                    matrix(c(80, 10,                                     # excited
                             50, 10,
                             20, 10), byrow = TRUE, ncol = 2, nrow = m), 
                    matrix(c(80, 10,                                     # relaxed
                             50, 10,
                             20, 10), byrow = TRUE, ncol = 2, nrow = m), 
                    matrix(c(80, 10,                                     # satisfied
                             50, 10,
                             20, 10), byrow = TRUE, ncol = 2, nrow = m), 
                    matrix(c(10,  5,                                     # angry
                             30, 10,
                             50, 15), byrow = TRUE, ncol = 2, nrow = m), 
                    matrix(c(10,  5,                                     # anxious
                             30, 10,
                             50, 15), byrow = TRUE, ncol = 2, nrow = m), 
                    matrix(c(10,  5,                                     # depressed
                             30, 10,
                             50, 15), byrow = TRUE, ncol = 2, nrow = m), 
                    matrix(c(10,  5,                                     # sad
                             30, 10,
                             50, 15), byrow = TRUE, ncol = 2, nrow = m))

## specifying weakly informative prior for continuous emission distributions
emotion_prior_emiss_3st <- prior_emiss_cont(
  gen = list(m = m, n_dep = n_dep),
  emiss_mu0 = list(matrix(c(80, 50, 20), nrow = 1),  # happy
                   matrix(c(80, 50, 20), nrow = 1),  # excited
                   matrix(c(80, 50, 20), nrow = 1),  # relaxed
                   matrix(c(80, 50, 20), nrow = 1),  # satisfied
                   matrix(c(10, 30, 50), nrow = 1),  # angry
                   matrix(c(10, 30, 50), nrow = 1),  # anxious
                   matrix(c(10, 30, 50), nrow = 1),  # depressed
                   matrix(c(10, 30, 50), nrow = 1)), # sad 
  emiss_K0 = rep(list(1), n_dep),
  emiss_V = rep(list(rep(5^2, m)), n_dep),
  emiss_nu = rep(list(1), n_dep),
  emiss_a0 = rep(list(rep(1.5, m)), n_dep),
  emiss_b0 = rep(list(rep(20, m)), n_dep),
)
```

```{r, echo = TRUE}
####################
# 4 state model
####################

## general model properties
m <- 4
n_dep <- 8

## starting values for gamma
start_gamma_4st <- matrix(c(0.7, 0.1, 0.1, 0.1,
                            0.1, 0.7, 0.1, 0.1,
                            0.1, 0.1, 0.7, 0.1,
                            0.1, 0.1, 0.1, 0.7), byrow = TRUE, ncol = m, nrow = m)

## starting values for the emission distribution 
start_emiss_4st <- list(matrix(c(80, 10,                                     # happy
                             60, 10,
                             40, 10,
                             20, 10), byrow = TRUE, ncol = 2, nrow = m), 
                    matrix(c(80, 10,                                     # excited
                             60, 10,
                             40, 10,
                             20, 10), byrow = TRUE, ncol = 2, nrow = m), 
                    matrix(c(80, 10,                                     # relaxed
                             60, 10,
                             40, 10,
                             20, 10), byrow = TRUE, ncol = 2, nrow = m), 
                    matrix(c(80, 10,                                     # satisfied
                             60, 10,
                             40, 10,
                             20, 10), byrow = TRUE, ncol = 2, nrow = m), 
                    matrix(c(10,  5,                                     # angry
                             20, 10,
                             40, 10,
                             60, 10), byrow = TRUE, ncol = 2, nrow = m), 
                    matrix(c(10,  5,                                     # anxious
                             320, 10,
                             40, 10,
                             60, 10), byrow = TRUE, ncol = 2, nrow = m), 
                    matrix(c(10,  5,                                     # depressed
                             20, 10,
                             40, 10,
                             60, 10), byrow = TRUE, ncol = 2, nrow = m), 
                    matrix(c(10,  5,                                     # sad
                             20, 10,
                             40, 10,
                             60, 10), byrow = TRUE, ncol = 2, nrow = m))

## specifying weakly informative prior for continuous emission distributions
emotion_prior_emiss_4st <- prior_emiss_cont(
  gen = list(m = m, n_dep = n_dep),
  emiss_mu0 = list(matrix(c(80, 60, 40, 20), nrow = 1),  # happy
                   matrix(c(80, 60, 40, 20), nrow = 1),  # excited
                   matrix(c(80, 60, 40, 20), nrow = 1),  # relaxed
                   matrix(c(80, 60, 40, 20), nrow = 1),  # satisfied
                   matrix(c(10, 20, 40, 60), nrow = 1),  # angry
                   matrix(c(10, 20, 40, 60), nrow = 1),  # anxious
                   matrix(c(10, 20, 40, 60), nrow = 1),  # depressed
                   matrix(c(10, 20, 40, 60), nrow = 1)), # sad 
  emiss_K0 = rep(list(1), n_dep),
  emiss_V = rep(list(rep(5^2, m)), n_dep),
  emiss_nu = rep(list(1), n_dep),
  emiss_a0 = rep(list(rep(1.5, m)), n_dep),
  emiss_b0 = rep(list(rep(20, m)), n_dep),
)

```

```{r, include = params$answers, eval = FALSE}
# Fitting the 3 state model 
m <- 3
out_3st_emotion <- mHMM(s_data = emotion_mHMM,
                        data_distr = "continuous",
                        gen = list(m = m, n_dep = n_dep),
                        start_val = c(list(start_gamma_3st), start_emiss_3st),
                        emiss_hyp_prior = emotion_prior_emiss_3st,
                        mcmc = list(J = 500, burn_in = 200))

# Fitting the 4 state model 
m <- 4
out_4st_emotion <- mHMM(s_data = emotion_mHMM,
                        data_distr = "continuous",
                        gen = list(m = m, n_dep = n_dep),
                        start_val = c(list(start_gamma_4st), start_emiss_4st),
                        emiss_hyp_prior = emotion_prior_emiss_4st,
                        mcmc = list(J = 500, burn_in = 200))

```

```{r, echo  = FALSE}
out_3st_emotion <- readRDS("./data/out_3st_emotion.rds")
out_4st_emotion <- readRDS("./data/out_4st_emotion.rds")
```
---


---

**Exercise 2**
Inspect the general output of the 3- and 4- state models by using the inbuilt `print()` and `summary()` for objects of class `mHMM` returned by the function `mHMM()`.

```{r, include = params$answers}
# 3 state model 
out_3st_emotion
summary(out_3st_emotion)

# 4 state model 
out_4st_emotion
summary(out_4st_emotion)
```

---

### Inspect the state composition of the fitted models

First, we will investigate the composition of the states, and use this to evaluate whether it seems sensible to add extra states. Especially with multivariate data, inspecting the composition of the states is done most easily visually. 

---

**Exercise 3**
Use your code from practical 1 to visualize the group level emission distributions of the 3- and 4-state model and compare to the 2-state model. Note: remember to first save the emission distribution parameters in an object using the function `obtain_emiss()`. Does it seem to make sense to add extra state(s)?

```{r, include = params$answers, fig.height = 3}
###############
# 3 state model 
###############

emiss_group_3st <- obtain_emiss(out_3st_emotion)
m <- 3
## plotting group level emissions, bar plot
## reshaping data for ggplot to make one plot simultaneously for all dependent variables 
## meaning: one matrix containing all state and variable dependent means, with state and mood as variable 
emiss_group_3st <- lapply(emiss_group_3st, function(x,m){rownames(x) <- paste0(1:m);x}, m = m)
emiss_group_melt_3st <- lapply(emiss_group_3st, melt)
emiss_group_melt_3st <- do.call(rbind, emiss_group_melt_3st)
emiss_group_melt_3st <- emiss_group_melt_3st[emiss_group_melt_3st$Var2 == "Mean", c(1, 3)]
colnames(emiss_group_melt_3st) <- c("State", "Mean")
emiss_group_melt_3st$Dep <- factor(c(rep(names(emiss_group_3st), each = m)), levels = names(emiss_group_3st))
emiss_group_melt_3st$State <- factor(emiss_group_melt_3st$State, label = 1:m)

## plot
ggplot(emiss_group_melt_3st, aes(x = State, y = Mean, fill = Dep)) +
         geom_bar(stat="identity") +
  facet_grid(cols = vars(Dep)) + 
  theme_minimal() +
  theme(legend.position="none") +
  xlab("Mood state")

# Note: although the first 2 states do not really differ for the postive affect measures, the first 2 states do differentiate on the negative affect variables. 

###############
# 4 state model 
###############

emiss_group_4st <- obtain_emiss(out_4st_emotion)
m <- 4
## plotting group level emissions, bar plot
## reshaping data for ggplot to make one plot simultaneously for all dependent variables 
## meaning: one matrix containing all state and variable dependent means, with state and mood as variable 
emiss_group_4st <- lapply(emiss_group_4st, function(x,m){rownames(x) <- paste0(1:m);x}, m = m)
emiss_group_melt_4st <- lapply(emiss_group_4st, melt)
emiss_group_melt_4st <- do.call(rbind, emiss_group_melt_4st)
emiss_group_melt_4st <- emiss_group_melt_4st[emiss_group_melt_4st$Var2 == "Mean", c(1, 3)]
colnames(emiss_group_melt_4st) <- c("State", "Mean")
emiss_group_melt_4st$Dep <- factor(c(rep(names(emiss_group_4st), each = m)), levels = names(emiss_group_4st))
emiss_group_melt_4st$State <- factor(emiss_group_melt_4st$State, label = 1:m)

## plot
ggplot(emiss_group_melt_4st, aes(x = State, y = Mean, fill = Dep)) +
         geom_bar(stat="identity") +
  facet_grid(cols = vars(Dep)) + 
  theme_minimal() +
  theme(legend.position="none") +
  xlab("Mood state")

# Note: the 4th state does differentate the emotions even more, but not as much as adding the third state. 
```

---

### Consider model selection criteria for guidance

Next, let's compare the 2-, 3-, and 4-state model on the model selection criteria AIC. 


---

**Exercise 4**
Obtain the AIC values of the 2-, 3-, and 4-state model using the `print()` function on the mHMM objects `out_2st_emotion`, `out_3st_emotion`, `out_4st_emotion`, and compare. Note: it can be helpful to visualize the AIC values over the states to get a feeling for how much the AIC decreases over the models. 

```{r, include = params$answers, fig.height=4}
out_2st_emotion
out_3st_emotion
out_4st_emotion

AICs <- data.frame(AIC = c(11657.01, 11453.64, 11357.04),
                   states = c(2:4))
ggplot(AICs, mapping = aes(x = states, y = AIC)) +
  geom_point() + 
  geom_line() +
  ggtitle("AIC over the 2 - 4 state models") + 
  xlab("Number of states") +
  theme_minimal()

```

---

As you can see, determining the number of states can be a subjective and tricky endeavor, and depends very much on the data and research question at hand.  

## Subject specific parameters

In this section, we obtain and inspect the subject specific parameters. To facilitate flexibility in the order of going through this practical, we will base our work (and the answers) on the 2-state model, but feel free to try this with any of the other number of states models. 

### Transition probabilities gamma
First, we need to obtain the subject specific paramters, and save the subject specific paramters in an object. When focusing on the transition probabilities gamma, the function `obtain_gamma()` can also be used to obtain the subject specific transition probabilites, by setting the input argument `level` to `"subject"`. Note that the default of `level` is `"group"`, so when left unspecified, the function `obtain_gamma()` will return the group level transition probabilities. 

---

**Exercise 5**
Obtain the subject specific transition probabilities using the function `obtain_gamma()` and set the input argument `level` to `"subject"`. Save the output in the object `gamma_subject`. Inspect the output. 

```{r, include = params$answers}
# obtaining and saving the subject specific transition probabilities
gamma_subject <- obtain_gamma(out_2st_emotion, level = "subject")

# inspecting the output, restring the returned output to the first 10 subjects
gamma_subject[1:10]
```

Note that it can be quite insightful to compare the subject specific transition probabilities to the plotted state sequences. Subjects with large self-transitions (i.e., probabilities that denote a transition to the same state as the current state, provided on the diagonal of the transition probability matrix) will probably remain for a long time within a state, while low self-transition probabilities most likely will translate to state sequences where a state is only visited for a short consequitive sequence.   

---

To develop an intuition on how much the transition probabilities vary over subjects, it can be helpful to plot the subject specific state transition probabilities, for example in a heath map with one row per subject, or in stacked dots with a dot for each subject specific transition probability, and columns for each of the possible state transitions. 

---

**Exercise 6**
Plot (a subset of) the subject specific transition probabilities, and investigate how much the transition probabilities differ over subjects. 

```{r, include = params$answers, fig.height=20}
m <- 2
n_subj <- out_2st_emotion$input$n_subj

# reshaping data for ggplot
gg_gamma_subject <- data.frame(Subj = factor(rep(1:n_subj, each = m * m), levels = 1:n_subj),
                               From_to = factor(paste("From", rep(1:m, m * n_subj), 
                                                      "to", rep(rep(1:m, each = m), n_subj))), 
                               Prob = unlist(t(gamma_subject)))

# we plot the data for the first 50 subjects here 
ggplot(data = gg_gamma_subject[gg_gamma_subject$Subj %in% c(1:50),], aes(x=From_to, y = Subj , fill=Prob)) + 
  geom_tile(color = "white") +
  scale_fill_distiller(palette = "Spectral", limits = c(0,1), name = "State switching\n probability") +
  geom_text(aes(From_to, Subj, label = round(Prob,2)), color = "darkslategrey", size = 3) +
  theme_minimal()+ 
  ylab("Subject") + xlab(element_blank()) + 
  scale_y_discrete(limits=rev) +
  coord_fixed() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))

```

---

### Emission distribution 
Again, we first need to obtain the subject specific emission distribution parameters, and save the subject specific parameters in an object. When focusing on the emission distribution parameters, the function `obtain_emiss()` can be used to obtain the subject specific emission distribution parameters, by setting the input argument `level` to `"subject"`. Note that the default of `level` is `"group"`, so when left unspecified, the function `obtain_emiss()` will return the group level emission distribution parameters. 

---

**Exercise 7**
Obtain the subject specific emission distribution parameters using the function `obtain_emiss()` and set the input argument `level` to `"subject"`. Save the output in the object `emiss_subject`. Inspect the output. 

```{r, include = params$answers}
# obtaining and saving the subject specific transition probabilities
emiss_subject <- obtain_emiss(out_2st_emotion, level = "subject")
```

---

Again, to develop an intuition on how much the emission distribution parameters (e.g., the variable and state specific means) vary over subjects, it can be helpful to plot the subject specific emission distribution parameters, for example by adding the subject specific parameters as dots to a group level barplot of the emission means. 

---

**Exercise 8**
Plot (a subset of) the subject specific  emission distribution means, and investigate how much the means differ over subjects. 

```{r, include = params$answers, fig.height=4}
m <- 2
n_subj <- out_2st_emotion$input$n_subj
n_dep <- 8

# reshaping data for ggplot
vars <- names(emiss_subject)
gg_emiss_subject <- data.frame(Subj = rep(rep(1:n_subj, each = m), n_dep),
                               State = rep(1:m, n_subj * n_dep), 
                               Dep = factor(c(rep(vars, each = m * n_subj)), levels = vars))

gg_emiss_subject$Mean <-c(unlist(lapply(emiss_subject[[1]], "[", 1:m)), 
                          unlist(lapply(emiss_subject[[2]], "[", 1:m)),
                          unlist(lapply(emiss_subject[[3]], "[", 1:m)),
                          unlist(lapply(emiss_subject[[4]], "[", 1:m)),
                          unlist(lapply(emiss_subject[[5]], "[", 1:m)),
                          unlist(lapply(emiss_subject[[6]], "[", 1:m)),
                          unlist(lapply(emiss_subject[[7]], "[", 1:m)),
                          unlist(lapply(emiss_subject[[8]], "[", 1:m)))

emiss_group <- obtain_emiss(out_2st_emotion)
emiss_group <- lapply(emiss_group, function(x,m){rownames(x) <- paste0(1:m);x}, m = m)
emiss_group_melt <- lapply(emiss_group, melt)
emiss_group_melt <- do.call(rbind, emiss_group_melt)
emiss_group_melt <- emiss_group_melt[emiss_group_melt$Var2 == "Mean", c(1, 3)]
colnames(emiss_group_melt) <- c("State", "Mean")
emiss_group_melt$Dep <- factor(c(rep(vars, each = m)), levels = names(emiss_group))
emiss_group_melt$State <- factor(emiss_group_melt$State, label = 1:m)

## plot
ggplot(emiss_group_melt, aes(x = State, y = Mean, fill = Dep)) +
  geom_bar(stat="identity") +
  geom_jitter(data = gg_emiss_subject, aes(x = State, y = Mean, fill = Dep), 
              alpha = 0.5, colour="black",pch=21) +
  facet_grid(cols = vars(Dep)) + 
  theme_minimal() +
  theme(legend.position="none") +
  xlab("Mood state")

```

---

In addition, it is important to check that the states represent the same construct over subjects. Working with our current dataset, that would mean that for each subject, state 1 represents a 'good mood' state, and state 2 represents a 'bad mood' state. Fore example, for the indicator *happy*, that would translate to the mean of state 1 being higher compared to state 2. Visually, this can be checked by connecting the subject specific means over the states within one indicator by lines. 

---

**Exercise 9**
Plot (a subset of) the subject specific emission distribution means connecting the subject specific means, and visually investigate whether the state 1 is a relatively good state and state 2 a relatively bad state over subjects. 

```{r, include = params$answers, fig.height=4}
## plot, first 50 subjects to aid interpretability
ggplot(emiss_group_melt, aes(x = State, y = Mean, fill = Dep)) +
  geom_bar(stat="identity") +
  geom_point(data = gg_emiss_subject[gg_emiss_subject$Subj %in% 1:50,], aes(x = State, y = Mean, fill = Dep), 
             alpha = 0.5, colour="black",pch=21) +
  geom_line(data = gg_emiss_subject[gg_emiss_subject$Subj %in% 1:50,], aes(x = State, y = Mean, group = Subj), color = "grey", alpha = 0.5) +
  facet_grid(cols = vars(Dep)) + 
  theme_minimal() +
  theme(legend.position="none") +
  xlab("Mood state")

```

---


## Covariates 
In this section we will see if we can explain the differences observed in the subject specific state transition probabilities by the covariate `group`. Group = 1 denotes the subjects that received mindfulness training, while group = 2 represents the subjects that were in a waiting list control group. 

Covariates are specified to the model as a list, where the first element in the list is used to predict the transition matrix. Subsequent elements in the list are used to predict the emission distribution of (each of) the dependent variable(s). As we only want to predict the transition matrix, the subsequent lists will be set to `NULL`. Each (non-null) element in the list is a matrix, with only one row per subject. The first column consists of only ones (representing the intercept), and the subsequent columns contain the covariate(s).  

---

**Exercise 10**
Compose the list containing the covariate in the correct format. To speed up the process, a starter script is given below. Note that the covariate `group` is contained in the dataset `emotion_data`, and still needs to be condensed to only one input per subject. In addition, note that a dichotomous covariate needs to be codes as 0 / 1, so the group variable containing the values 1 and 2 still need to be transformed to only contain the values 0 and 1. 

```{r, eval = FALSE}
# specify a list with the correct number of elements, where all elements are set to NULL
covariate <- vector("list", length = 1 + n_dep)

# specify the first element of the list, where the first column consists of ones only,  
# the second column contains the covariate group, with only one entry per subject
n_subj <- out_2st_emotion$input$n_subj
covariate[[1]] <- matrix(c(rep(1,n_subj), 
                           [INPUT THE COVARIATE HERE]), byrow = FALSE, ncol = 2)

```

```{r, include = params$answers }
# specify a list with the correct number of elements, where all elements are set to NULL
covariate <- vector("list", length = 1 + n_dep)

# extract the covariate `group`
group <- apply(table(emotion_data$subj_id, emotion_data$group), 1, which.max)
group <- group - 1

# specify the first element of the list, where the first column consists of ones only,  
# the second column contains the covariate group, with only one entry per subject
n_subj <- out_2st_emotion$input$n_subj
covariate[[1]] <- matrix(c(rep(1,n_subj), 
                           group), byrow = FALSE, ncol = 2)
covariate

```

---

Now, let's fit a 2-state multilevel HMM including the covariate `group` to predict the subject specific state transition probabilities. Note that we can re-use the specified starting values and hyper-prior value specification for the emission distribution from practical 1. 

---

**Exercise 11**
fit a 2-state multilevel HMM including the covariate `group`, and save the fitted model in the object `out_2st_emotion_cov`. The input argument for specifying a covariate within the function `mHMM()` is `xx`. 

```{r, include = params$answers, eval = FALSE}
m <- 2
n_dep <- 8

start_gamma <- matrix(c(0.7, 0.3, 
                        0.3, 0.7), byrow = TRUE, ncol = m, nrow = m)

start_emiss <- list(matrix(c(70, 15,                                     # happy
                             30, 15), byrow = TRUE, ncol = 2, nrow = m), 
                    matrix(c(70, 15,                                     # excited
                             30, 15), byrow = TRUE, ncol = 2, nrow = m), 
                    matrix(c(70, 15,                                     # relaxed
                             30, 15), byrow = TRUE, ncol = 2, nrow = m), 
                    matrix(c(70, 15,                                     # satisfied
                             30, 15), byrow = TRUE, ncol = 2, nrow = m), 
                    matrix(c(15, 10,                                     # angry
                             40, 15), byrow = TRUE, ncol = 2, nrow = m), 
                    matrix(c(15, 10,                                     # anxious
                             40, 15), byrow = TRUE, ncol = 2, nrow = m), 
                    matrix(c(15, 10,                                     # depressed
                             40, 15), byrow = TRUE, ncol = 2, nrow = m), 
                    matrix(c(15, 10,                                     # sad
                             40, 15), byrow = TRUE, ncol = 2, nrow = m))

emotion_prior_emiss <- prior_emiss_cont(
  gen = list(m = m, n_dep = n_dep),
  emiss_mu0 = list(matrix(c(70, 30), nrow = 1),  # happy
                   matrix(c(70, 30), nrow = 1),  # excited
                   matrix(c(70, 30), nrow = 1),  # relaxed
                   matrix(c(70, 30), nrow = 1),  # satisfied
                   matrix(c(15, 40), nrow = 1),  # angry
                   matrix(c(15, 40), nrow = 1),  # anxious
                   matrix(c(15, 40), nrow = 1),  # depressed
                   matrix(c(15, 40), nrow = 1)), # sad 
  emiss_K0 = rep(list(1), n_dep),
  emiss_V = rep(list(rep(5^2, m)), n_dep),
  emiss_nu = rep(list(1), n_dep),
  emiss_a0 = rep(list(rep(1.5, m)), n_dep),
  emiss_b0 = rep(list(rep(20, m)), n_dep),
)


out_2st_emotion_cov <- mHMM(s_data = emotion_mHMM,
                        data_distr = "continuous",
                        gen = list(m = m, n_dep = n_dep),
                        xx = covariate,
                        start_val = c(list(start_gamma), start_emiss),
                        emiss_hyp_prior = emotion_prior_emiss,
                        mcmc = list(J = 500, burn_in = 200))
```

```{r, echo = FALSE}
out_2st_emotion_cov <- readRDS("./data/out_2st_emotion_cov.rds")
```

---

Note: when using covariates, the specification of the hyper-prior values changes for that component of the model. In this example, we only specified a covariate predicting the transition probabilities, and as we did not specify specif hyper-prior values for the transition probabilities (i.e., we used the default prior specifications inbuilt within the `mHMMbayes` package for the transition probabilities gamma), nothing changed for the prior specification of the emission distribution. However, please note that if we were to use the covariate to explain differences in the subject specific emission distribution, the hyper prior value specification using `prior_emiss_cont()` function would change. See the help file of this function for more information. 

---

**Exercise 12**
Inspect the general output of the 2-state model including the covariate by using the inbuilt `print()` and `summary()` for objects of class `mHMM` returned by the `mHMM()` function. 

```{r, include = params$answers}
out_2st_emotion_cov
summary(out_2st_emotion_cov)

```

---

As you can see, the package currently does not yet include information on the output of the covariate in the `print()` and `summary()` functions. For covariates on the transition probabilities, parameter estimates related to the covariate(s) are contained in the list named `gamma_cov_bar` included in the output object. For covariates on the emission distribution, parameter estimates related to the covariate(s) are contained in the list named `emiss_cov_bar` (when modelling continuous output, see the function `mHMM()` help file for more information). To be specific, `gamma_cov_bar` is a matrix containing the group level regression coefficients of the Multinomial logistic regression predicting the transition probabilities over the iterations of the hybrid Metropolis within Gibbs sampler. The iterations of the sampler are contained in the rows, and the columns contain the group level regression coefficients. Note that as we are using the multinomial logit transformation of the probabilities, the first state in each row of the transition probability matrix serves as a reference category, and does not have a regression coefficient. 

---

**Exercise 13**
Inspect the regression coefficients related to the covariate `group` using the starter script below. Using the script, you will obtain a summary of the posterior distribution over the MCMC iterations: the mode and the lower and upper limit of the 95\% credibility interval. In case that the credibility interval does not contain zero, it can be seen as a strong indicator that the covariate `group` is indeed related to the subject specific transition probabilities. In addition, a positive regression coefficient signals that for the group coded as 1, the transition probability from state 1 to state 2, and from state 2 to state 2 are increased. A negative regression coefficient ignals that for the group coded as 1, the transition probability from state 1 to state 2, and from state 2 to state 2 are decreased.

```{r, eval = FALSE}
burn_in <- ... # fill in the burn-in period you specified in mHMM()
J <- ...       # fill in the number of MCMC iterations you specified in mHMM()

summary_covariate <- data.frame(median =                                    
                                  apply(out_2st_emotion_cov$gamma_cov_bar[burn_in:J,], 2, median),
                                lower_CrI = 
                                  apply(out_2st_emotion_cov$gamma_cov_bar[burn_in:J,], 2, quantile, 0.025),
                                upper_CrI =
                                  apply(out_2st_emotion_cov$gamma_cov_bar[burn_in:J,], 2, quantile, 0.975))

summary_covariate
```

```{r, include = params$answers}
burn_in <- 200
J <- 500

summary_covariate <- data.frame(median =                                    
                                  apply(out_2st_emotion_cov$gamma_cov_bar[burn_in:J,], 2, median),
                                lower_CrI = 
                                  apply(out_2st_emotion_cov$gamma_cov_bar[burn_in:J,], 2, quantile, 0.025),
                                upper_CrI =
                                  apply(out_2st_emotion_cov$gamma_cov_bar[burn_in:J,], 2, quantile, 0.975))

summary_covariate
```

---

As you can see, the covariate `group` is does not explain the heterogeneity we observe in the subject specific transition probability parameters. This is in line with the original paper, where they also did not find an effect of mindfulness training on the mood factors, albeit tested in a different manner. 

## Model fit
In this section we will inspect model fit, checking convergence and using posterior predictive checks (PPCs). 

### Convergence
Within any Bayesian analysis, convergence needs to be assessed in order to rule out output resulting from a local (instead of global) maximum. To check this, multiple chains (at least 2) need to be run, performing the same analysis but using (slightly) different starting values in each chain. Note that in multilevel hidden Markov models, it is important to still keep sensible starting values when varying these. For example, when modelling continuous or count data, we need to keep the same sensible ordering of $\bar{\mu}_i$ or $\bar{\lambda}_i$ given data and process.  Values of the weakly informative prior distributions should be fixed over the chains.

---

**Exercise 14**
Fit at least one additional chain for the 2 state multilevel HMM model specifying new starting values, and save each new fitted model in a new object, e.g., `out_2st_emotion_b`.

```{r, include = params$answers, eval = FALSE}
m <- 2
n_dep <- 8

start_gamma_b <- matrix(c(0.9, 0.1, 
                        0.1, 0.9), byrow = TRUE, ncol = m, nrow = m)

start_emiss_b <- list(matrix(c(80, 10,                                     # happy
                             40, 15), byrow = TRUE, ncol = 2, nrow = m), 
                    matrix(c(80, 10,                                     # happy
                             40, 15), byrow = TRUE, ncol = 2, nrow = m), 
                    matrix(c(80, 10,                                     # happy
                             40, 15), byrow = TRUE, ncol = 2, nrow = m), 
                    matrix(c(80, 10,                                     # happy
                             40, 15), byrow = TRUE, ncol = 2, nrow = m), 
                    matrix(c(5, 5,                                     # angry
                             30, 15), byrow = TRUE, ncol = 2, nrow = m), 
                    matrix(c(5, 5,                                     # angry
                             30, 15), byrow = TRUE, ncol = 2, nrow = m), 
                    matrix(c(5, 5,                                     # angry
                             30, 15), byrow = TRUE, ncol = 2, nrow = m), 
                    matrix(c(5, 5,                                     # angry
                             30, 15), byrow = TRUE, ncol = 2, nrow = m))


out_2st_emotion_b <- mHMM(s_data = emotion_mHMM,
                        data_distr = "continuous",
                        gen = list(m = m, n_dep = n_dep),
                        start_val = c(list(start_gamma_b), start_emiss_b),
                        emiss_hyp_prior = emotion_prior_emiss,
                        mcmc = list(J = 500, burn_in = 200))

```

```{r, echo = FALSE}
out_2st_emotion_b <- readRDS("./data/out_2st_emotion_b.rds")
```

---

Evidence for non convergence can be checked in multiple ways. Visually, using trace plots which visualize the parameter estimates over the iterations of the MCMC sampler. The chains should not show any trend and good mixing. Or numerically, with the potential scale reduction factor $\hat{R}$. $\hat{R}$ tests for equality of means of the different chains - the degree to which variance (of the means) between chains exceeds what one would expect if the chains were identically distributed. A value of R-hat below 1.2 is used to indicate convergence. 

For the group level transition probabilities gamma, we will show how to obtain the traceplots. The information on the parameter estimates on the group level transition probabilities over the MCMC iterations are contained in the list `gamma_prob_bar` included in the returned output object when using the function `mHMM()`. 

---

**Exercise 14**
Using the starter script below, inspect the traceplots of the group level transition probabilities. 
```{r, eval = FALSE}
burn_in <- ... # fill in the burn-in period you specified in mHMM()
J <- ...       # fill in the number of MCMC iterations you specified in mHMM()

data1 <- out_2st_emotion
data2 <- out_2st_emotion_b
# Optionally, you can add more chains here, e.g.,:
# data3 <- out_2st_emotion_c

par(mfrow = c(m,m))
for(i in 1:m){
  for(j in 1:m){
    plot(data1$gamma_prob_bar[,(j + ((i-1) * m))], type = "l", 
         main = paste("From", i, "to", j), 
         ylim = c(0,1), col = "coral", ylab = "transition probability", xlab = "iteration")
    lines(data2$gamma_prob_bar[,(j + ((i-1) * m))], col = "cornflowerblue")
    # lines(data3$gamma_prob_bar[,(j + ((i-1) * m))], col = "green")
    abline(h = mean(data1$gamma_prob_bar[((burn_in + 1): J),(j + ((i-1) * m))]), col = "coral")
    abline(h = mean(data2$gamma_prob_bar[((burn_in + 1) : J),(j + ((i-1) * m))]), col = "cornflowerblue")
    # abline(h = mean(data3$gamma_prob_bar[((burn_in + 1) : J),(j + ((i-1) * m))]), col = "green")
  }
}

```

```{r, include = params$answers}
burn_in <- 200
J <- 500

data1 <- out_2st_emotion
data2 <- out_2st_emotion_b
# Optionally, you can add more chains here, e.g.,:
# data3 <- out_2st_emotion_c

par(mfrow = c(m,m))
for(i in 1:m){
  for(j in 1:m){
    plot(data1$gamma_prob_bar[,(j + ((i-1) * m))], type = "l", 
         main = paste("From", i, "to", j), 
         ylim = c(0,1), col = "coral", ylab = "transition probability", xlab = "iteration")
    lines(data2$gamma_prob_bar[,(j + ((i-1) * m))], col = "cornflowerblue")
    # lines(data3$gamma_prob_bar[,(j + ((i-1) * m))], col = "green")
    abline(h = mean(data1$gamma_prob_bar[((burn_in + 1): J),(j + ((i-1) * m))]), col = "coral")
    abline(h = mean(data2$gamma_prob_bar[((burn_in + 1) : J),(j + ((i-1) * m))]), col = "cornflowerblue")
    # abline(h = mean(data3$gamma_prob_bar[((burn_in + 1) : J),(j + ((i-1) * m))]), col = "green")
  }
}

```

Note that in addition to the group level parameters, it is also important to check convergence at the subject level. However, this is beyond the current practical. 

---

For the means of the emission distributions, we will show how to calculate $\hat{R}$. The information on the group level emission distribution means over the MCMC iterations are contained in the list `emiss_mu_bar` included in the returned output object when using the function `mHMM()`. 

---

**Exercise 15**
Using the starter script below, inspect the $\hat{R}$ values of the group level emission distribution means. 
 
```{r, eval = FALSE}
burn_in <- ... # fill in the burn-in period you specified in mHMM()
J <- ...       # fill in the number of MCMC iterations you specified in mHMM()
n_dep <-  ...  # fill in the number of dependent variables used in mHMM()
n_chain <- ... # fill in the number of chains used (in the example, 2)
  
data1 <- out_2st_emotion
data2 <- out_2st_emotion_b
# Optionally, you can add more chains here, e.g.,:
# data3 <- out_2st_emotion_c

L <- J - burn_in

emiss_mean_data1 <- emiss_mean_data2 <- emiss_grand_mean <- #  <- emiss_mean_data3
  emiss_between_chain_var <- emiss_within_chain_var_d1 <- emiss_within_chain_var_d2 <- #emiss_within_chain_var_d3 <-
  emiss_W <- emiss_GelRub <- vector(mode = "list", n_dep)
for(j in 1:n_dep){
    emiss_mean_data1[[j]] <- apply(data1$emiss_mu_bar[[j]][((burn_in + 1) : J),], 2, mean)
    emiss_mean_data2[[j]] <- apply(data2$emiss_mu_bar[[j]][((burn_in + 1) : J),], 2, mean)
    # emiss_mean_data3[[j]] <- apply(data3$emiss_mu_bar[[j]][((burn_in + 1) : J),], 2, mean)
    emiss_grand_mean[[j]] <- (emiss_mean_data1[[j]] + emiss_mean_data2[[j]]) # + emiss_mean_data3[[j]]) 
    / n_chain
    emiss_between_chain_var[[j]] <- L / (n_chain-1) * ((emiss_mean_data1[[j]] - emiss_grand_mean[[j]])^2 + 
                                                         (emiss_mean_data2[[j]] - emiss_grand_mean[[j]])^2 +
                                                      # (emiss_mean_data3[[j]] - emiss_grand_mean[[j]])^2
                                                        )
    emiss_within_chain_var_d1[[j]] <- (1 / (n_chain-1)) * apply(data1$emiss_mu_bar[[j]][((burn_in + 1) : J),], 2, var)
    emiss_within_chain_var_d2[[j]] <- (1 / (n_chain-1)) * apply(data2$emiss_mu_bar[[j]][((burn_in + 1) : J),], 2, var)
   # emiss_within_chain_var_d3[[j]] <- (1 / (n_chain-1)) * apply(data3$emiss_mu_bar[[j]][((burn_in + 1) : J),], 2, var)
    emiss_W[[j]] <- (1/n_chain) * (emiss_within_chain_var_d1[[j]] + emiss_within_chain_var_d2[[j]] # + emiss_within_chain_var_d3[[j]]
                                   )
    
    emiss_GelRub[[j]] <- sqrt(((L - 1)/ L * emiss_W[[j]] + 1/L *  emiss_between_chain_var[[j]] ) / emiss_W[[j]])
}

# Inspect the Gelman Rubin statistic Rhat over all dependent variables and states 
emiss_GelRub

# inspect the mean Gelman Rubin statistic Rhat 
mean(unlist(emiss_GelRub))

# inspect the percentage of Gelman Rubin statistic Rhat above 1.2 
sum(unlist(emiss_GelRub) > 1.2) / length(unlist(emiss_GelRub))


```

```{r, include = params$answers}
burn_in <- 200
J <- 500
n_dep <-  8
n_chain <- 2
  
data1 <- out_2st_emotion
data2 <- out_2st_emotion_b
# Optionally, you can add more chains here, e.g.,:
# data3 <- out_2st_emotion_c

L <- J - burn_in

emiss_mean_data1 <- emiss_mean_data2 <- emiss_grand_mean <- #  <- emiss_mean_data3
  emiss_between_chain_var <- emiss_within_chain_var_d1 <- emiss_within_chain_var_d2 <- #emiss_within_chain_var_d3 <-
  emiss_W <- emiss_GelRub <- vector(mode = "list", n_dep)
for(j in 1:n_dep){
    emiss_mean_data1[[j]] <- apply(data1$emiss_mu_bar[[j]][((burn_in + 1) : J),], 2, mean)
    emiss_mean_data2[[j]] <- apply(data2$emiss_mu_bar[[j]][((burn_in + 1) : J),], 2, mean)
    # emiss_mean_data3[[j]] <- apply(data3$emiss_mu_bar[[j]][((burn_in + 1) : J),], 2, mean)
    emiss_grand_mean[[j]] <- (emiss_mean_data1[[j]] + emiss_mean_data2[[j]]) / n_chain
    emiss_between_chain_var[[j]] <- L / (n_chain-1) * ((emiss_mean_data1[[j]] - emiss_grand_mean[[j]])^2 + 
                                                         (emiss_mean_data2[[j]] - emiss_grand_mean[[j]])^2 # +
                                                      # (emiss_mean_data3[[j]] - emiss_grand_mean[[j]])^2
                                                        )
    emiss_within_chain_var_d1[[j]] <- (1 / (n_chain-1)) * apply(data1$emiss_mu_bar[[j]][((burn_in + 1) : J),], 2, var)
    emiss_within_chain_var_d2[[j]] <- (1 / (n_chain-1)) * apply(data2$emiss_mu_bar[[j]][((burn_in + 1) : J),], 2, var)
   # emiss_within_chain_var_d3[[j]] <- (1 / (n_chain-1)) * apply(data3$emiss_mu_bar[[j]][((burn_in + 1) : J),], 2, var)
    emiss_W[[j]] <- (1/n_chain) * (emiss_within_chain_var_d1[[j]] + emiss_within_chain_var_d2[[j]] # + emiss_within_chain_var_d3[[j]]
                                   )
    
    emiss_GelRub[[j]] <- sqrt(((L - 1)/ L * emiss_W[[j]] + 1/L *  emiss_between_chain_var[[j]] ) / emiss_W[[j]])
}

# Inspect the Gelman Rubin statistic Rhat over all dependent variables and states 
emiss_GelRub

# inspect the mean Gelman Rubin statistic Rhat 
mean(unlist(emiss_GelRub))

# inspect the percentage of Gelman Rubin statistic Rhat above 1.2 
sum(unlist(emiss_GelRub) > 1.2) / length(unlist(emiss_GelRub))

```

### PPCs

Finally, we will assess whether the model recovers the data correctly with respect to the mean and standard deviation, to reveal potential model missspecification. First, we need to generate simulated data sets based on obtained parameter estimates. The function `sim_mHMM()` can be used to simulate data using a multilevel hidden Markov model. 

---

**Exercise 16**
Use the starter script below to simulate 100 datasets based on the model parameters of the 2-state multilevel HMM. 

```{r, eval = FALSE}
n_sim <- 100 # for now, we will use 100 simulated datasets, but feel free to change. 
sim_datasets <- vector("list", n_sim)

m <- ...        # specify the number of states 
n_dep <- ...    # specify the number of dependent variables used in mHMM()

# calculate variance in emission distribution
sapply((out_2st_emotion$emiss_varmu_bar), apply, 2, mean, na.rm = TRUE)

for(i in 1:n_sim){
  sim_datasets[[i]] <- sim_mHMM(n_t = ... , # specify the number of beeps per subject
                                n = ...,    # specify the number of subjects  
                                data_distr = "continuous",
                                gen = list(m = m, n_dep = n_dep),
                                gamma = ... ,   # specify the obtained transition prob matrix 
                                emiss_distr = ... , # specify the emission distribution, see help file
                                var_gamma = 0.01,
                                var_emiss = c(300, 300, 300, 300, 100, 200, 200, 200)
  )
}



```

```{r, include = params$answers}
n_sim <- 100 
sim_datasets <- vector("list", n_sim)

m <- 2
n_dep <- 8

# calculate variance in emission distribution
sapply((out_2st_emotion$emiss_varmu_bar), apply, 2, mean, na.rm = TRUE)

for(i in 1:n_sim){
  sim_datasets[[i]] <- sim_mHMM(n_t = 240,
                                n = 125,
                                data_distr = "continuous",
                                gen = list(m = m, n_dep = n_dep),
                                gamma = matrix(c(0.81, 0.19,
                                                 0.33, 0.67), byrow = TRUE, ncol = m),  
                                emiss_distr = list(happy = matrix(c(67.54, 15.25,                     
                                                                    46.77, 22.41), byrow = TRUE, ncol = 2, nrow = m), 
                                                   excited = matrix(c(48.05, 23.61,                               
                                                                      30.87, 22.28), byrow = TRUE, ncol = 2, nrow = m), 
                                                   relaxed = matrix(c(62.26, 21.29,                             
                                                                      42.71, 24.53), byrow = TRUE, ncol = 2, nrow = m), 
                                                   satisfied = matrix(c(63.76, 18.71,                             
                                                                        40.39, 23.28), byrow = TRUE, ncol = 2, nrow = m), 
                                                   angry = matrix(c(5.84, 5.63,                                   
                                                                    26.85, 26.50), byrow = TRUE, ncol = 2, nrow = m),
                                                   anxious = matrix(c(6.04,  5.26,                               
                                                                      22.34, 25.58), byrow = TRUE, ncol = 2, nrow = m), 
                                                   depressed = matrix(c(11.55, 9.92,                             
                                                                        37.07, 26.90), byrow = TRUE, ncol = 2, nrow = m), 
                                                   sad = matrix(c(7.37, 7.06,                                   
                                                                  27.75, 25.40), byrow = TRUE, ncol = 2, nrow = m)) , 
                                var_gamma = 0.01,
                                var_emiss = c(300, 300, 300, 300, 100, 200, 200, 200)
  )
}


```

---

---

**Exercise 17**
For each simulated data set, calculate the summary statistics of interest (i.e., mean and standard deviation).

```{r, include = params$answers}
means_simdata <- matrix(, nrow = n_sim, ncol = n_dep)
for(i in 1:n_sim){
  means_simdata[i,] <- apply(sim_datasets[[i]]$obs[,2:(n_dep + 1)], 2, mean)
}

sd_simdata <- matrix(, nrow = n_sim, ncol = n_dep)
for(i in 1:n_sim){
  sd_simdata[i,] <- sqrt(apply(sim_datasets[[i]]$obs[,2:(n_dep + 1)], 2, var))
}
```

---

Now we have simulated datasets and obtained the summary characteristics, we will visually compare the characteristics of the simulated data to that of the observed data. 

---

**Exercise 18**
Plot the summary characteristics (mean and sd) of the simulated datasets in histograms, and add a vertical line for the mean and sd in the observed data to aid the comparison. 

```{r, include = params$answers}
vars <- names(obtain_emiss(out_2st_emotion))

par(mfrow = c(2,4))
for(i in 1:n_dep){
  hist(means_simdata[,i], 
       main = vars[i], 
       xlab = paste("Mean", vars[i]) 
  )
  abline(col = "red", lwd = 2, v = mean(emotion_data[,4+i], na.rm = TRUE))
}

# plot histogram sd simulated data and observed in real data
par(mfrow = c(2,4))
for(i in 1:n_dep){
  hist(sd_simdata[,i], 
       main = vars[i], 
       xlab = paste("SD", vars[i]), 
       xlim = c(20,30)
  )
  abline(col = "red", lwd = 2, v = sqrt(var(emotion_data[,4+i], na.rm = TRUE)))
}

# The means show no evidence of model fit, however the standard deviations of the simulated datasets are higher compared to the observed data. It would be interesting to see whether a 3-state model would partly solve this. 

```

---






